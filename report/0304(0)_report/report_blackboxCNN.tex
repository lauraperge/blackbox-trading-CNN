\documentclass[11pt, a4paper]{article}
\usepackage[english, science, titlepage]{ku-frontpage}
\usepackage[utf8]{inputenc}

\usepackage{cite}
\usepackage{natbib, apalike, url}

\setlength\arraycolsep{2 pt}
\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{0}

\assignment{Master Thesis}
\author{Laura Perge}

\title{Time Series Classification with CNN:}
\subtitle{ Automated Trading by Pattern Recognition}
\date{Handed in: \today}
\advisor{Advisors: Rolf Poulsen, Kenneth H. M. Nielsen, Lasse BÃ¸hling}
%\frontpageimage{example.png}

%% spellcheck-language "en"

\begin{document}
\maketitle

\tableofcontents

\begin{abstract}
    Something.
\end{abstract}

\section{Introduction}
People have been trading on financial markets for more than 200 years and with time, the internet, and technological advancement, the process has changed and evolved into what it is today:  
a versatile, international, online, easy-to-access, automated and truly immense beast. Its evolution is not over, however, and the mentioned features make it just the perfect subject of 
artificial intelligence and machine learning applications. 

But what were some major milestones of this evolution? As nicely summarized by \cite{rialtohistory}  employing algorithms in trading for calculation of asset prices goes back to the beginning of 
the 20th century. In the early 1950s, Harry Markowitz brought computational finance to existence in the pursuit of portfolio optimization. During that time, the computational 
resources were inadequate to efficiently utilize these algorithms in trading. From the 1970s to 1990s, 
large-scale computerization, the introduction of PCs, the internet and then amongst other systems the ECN (Electronic Communication Network) completely changed the game. Automation became a 
feasible solution, and algorithms are way faster to react with Buy/Sell orders on the market than humans. Trading is now not only for institutions or professionals and a chosen few but for 
every person with access to the internet. Intraday and high-frequency trading emerged and so, using algorithmic trading strategies with automated execution have become crucial in order to 
trade on these markets. 

There is another influential idea that has been around for several decades but has just gained space due to technological progress and the wide-spread access to computational power: artificial intelligence, more 
concisely machine learning and deep learning. 
The first paper about creating a model of the human neural networks was by \cite{mcculloch1943logical} and many more have followed ever since. 
One more achievement related to our topic was the first CNN (convolutional neural network) by \cite{fukushima1979neural} which is the first deep learning model for handwritten character and other 
pattern recognition.

CNN is an exceptionally popular tool nowadays, especially, in the field of image recognition, we will get back to the details about this in \ref{D&M:RecPatwCNN}.
The reasons to apply CNN for our problem is supported by both a bottom-up and top-down way. The top-down comes from the recently mentioned recognition of the technique which 
means plenty of resources, established and accurate models together with the ability of feature extraction which comes in handy for time series pattern recognition tasks. 
The bottom-up approach arises naturally from the idea of turning time series into images and label them, so these labels can be assigned to the new images later which, essentially, is 
just an image classification task. 

Nevertheless, when we look up ways of making money on financial markets the common approach appears to be forecasting time series adopting some traditional or more cutting-edge technique. 
Traditional means include autoregressive (AR) and/or moving average models (MA, ARMA) which are limited by the assumed linear relationship between the present and previous values of the univariate time series in question. 
Another limitation is the expectation of stationarity which is solved in the ARIMA (autoregressive integrated moving average) model that still remains linear but takes some preliminary transformation steps 
to turn the problem into a stationary ARMA. Although linearity is mostly acceptable in time series prediction problems, it is not true in all cases, and for that reason  
ARCH and GARCH (\textit{generalized} autoregressive conditional heteroskedasticity) models were invented. These complex models provided solutions to time series analytics which have long been in 
use and provide explicit insight into the time-dependence structure of the data.\footnote{The interested reader can find more information on these methods in for example Section 2 and 3 of \cite{tsay2005analysis}.}
In the field of AI and deep learning, recurrent neural networks (RNN) is a kind that was engineered to deal with sequential data. To address the issue of remembering long term temporal dependencies long 
short term memory (LSTM) networks were created which are heavily used in time series forecasting problems (\cite{Hochr97LSTM}). We will recount these topics in \ref{RW:ML&DL} in more granularity, 
however, we note that the reason why this paper chooses to avert from these procedures is that FINISH LATER!!!!!!!

But these models many times fail to predict prices and there is a higher error rate if we want to figure out tomorrows return... 
Therefore, our model will not predict the next element of the series, but it learns to recognize periods, in the end of which you should make a buying or selling order. (...)


\textbf{TO BE MODIFIED ACCORDING TO OUTCOME}
The goal of this paper is to develop a simple but powerful model that can make real-time trading decisions utilizing convolutional neural networks. For this, we need to capture as much dynamic 
and static information from the one-dimensional time series as possible which we achieve by turning them into images. The classification exercise requires labels which we choose to represent 
trading orders of "Buy", "Sell" and "Hold". 
These are preliminarily defined on the training set using a suitable algorithm that is designed to ensure profitability. The ultimate objective is a compact multilevel trading model that takes care of both the creation 
of image representations and the prediction of financially successful trading strategies using these images, for data that is fed to the model in real time. 
We should note, that this approach resembles the one recently published by \cite{sezer2018algorithmic} but the novelty represented in this paper lies in the methodology of 
the transformation of time series to images and our way of feeding them to the network. \textbf{(In the end we figure what are the differences really, but there should be quite a lot.
Keep stating innovations here.)}

In Section 2, we look at the path of publications that motivated and built the foundation of our approach. Then, Section 3 provides us with information about the kind of data we use throughout 
the paper, moreover, we introduce the methodologies implemented from the data preparation to the prediction phase. These include the transformation of one-dimensional time series into two-dimensional images, 
how we proceed to create appropriate labels for these images, how we construct and train our CNN model on them and return predictions using the model. Furthermore, we propose a solution for an 
actionable pipeline that could potentially be tailored to fit into a production environment.
Afterward, in Section 4 we examine the results and assess them in a three-fold manner:
technical fitness (how accurate is the classification?), financial profitability (how high are the returns?), swiftness (how quick is the model to come up with a prediction?). Section 5 concludes how much 
we closed in on grasping our objectives and what are some possible proceedings of this work.

\section{Related Work}


\subsection{Financial Time Series Analysis}
Forecasting, signal processing, time series pattern recognition

\subsection{Machine Learning \& Deep Learning}
\label{RW:ML&DL}

Main architectures, ANN, RNN, CNN, LSTM, Perceptrons..


\subsection{Algorithmic Trading}
Traditional Algorithmic Trading methodologies to new ones employing deep learning in: forecasting based / automated ways and limits

\section{Data and Methodology}
\subsection{Datasets}
Overview of datasets of different frequencies, asset classes that I use
Data cleaning steps
What data I need
Data transformation steps 
Potential other ways of using data

\subsection{Time Series to Image Transformation Strategies}
SHOULD BE EASY
Idea of transformation

GAF, RP (arvix.org/pdf/1710.00886.pdf 3.1 subsec), MTF
Show image outputs of different types
write about them 

\subsection{Image Labelling}
SHOULD BE EASY

Labelling: don't forget discrepancy in labelling algo vs image labels
Labelling algo: depends on window size

\subsection{Recognizing Patterns with Deep CNN}
\label{D&M:RecPatwCNN}
Deep convolutional neural networks (CNN) are artificial neural networks (ANN) with multiple layers between the input and output layers (deep) that also employ convolution in one or more layers 
as a substitute for the matrix multiplication (see p.326, Chapter 9 in \cite{goodfellow2016deep}). 
Chapter 9.2 of \cite{goodfellow2016deep}). 
Firstly, it can process fairly raw high dimensional data and extract the most important features for the given exercise. Secondly, the sparse connectivity in the network prove to be computationally very efficient . And last but not least, 

Let us take a second to recap what we have so far. We have one-dimensional historical stock price data that we preprocessed and created images from the sliding windows of data points. We created 
labels of trading actions on our original data and then matched these labels to the relevant images. 

How to classify the images, why CNN, \dots, 
Introduce your base model - NOT DOING THIS YET BUT SKELETON:

1. Feed image representations in different channels for colors

2. Optimize number of layers, neurons - maybe tiled CNN

3. Add regularization

4. See if you can change the loss function to be minus return

5. Other additions/optimization?

\subsection{Actionable Pipeline}

\section{Evaluation and Results}

\subsection{Classification Performance}
confusion matrix, accuracy measurements, etc.

\subsection{Financial Performance}
description of trading according to model, measurements and ratios
numbers (maybe against other trading algo)

\subsection{Time Consumption}
How long it takes to train, how long it takes to predict

\section{Conclusion}

\section{Appendices}
Calculations, explanations
Hyperparameter optimization Results
Other optimization results

\bibliography{reference}
\bibliographystyle{apalike}

\end{document}
