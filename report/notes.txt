FOR NEXT TIME:

->> then CNN (+Google Colab set up )
->> test data
->> then write relevant Intro, Data and Methodology Points 
->> if done add markov transition field to potential transformations and check that too


- data: FX is needed because stocks, S&P500, etc. only available on trading days: proposes issue of weekends (remember later when evaluating)
- algo: momentum based / trend following ones are interesting for our goal (look at this for starters: https://github.com/datacamp/datacamp-community-tutorials/blob/master/Python%20Finance%20Tutorial%20For%20Beginners/Python%20For%20Finance%20Beginners%20Tutorial.ipynb)
- GEMINI BTCUSD DATA: USE ONLY UNTIL 2018/08/23 01:50:00 some missing after
- backtesting: 
pitfalls: external events, liquidity constraints, model overfit, lookahead
components: strategy, P&L calc.
- for later: cross validation and model selection (approach - ts or we can ignore the fact that it is ts)
- careful with lookahead bias (even at the time of normalization)
- when labelling data: window size determines the size of trend windows recognized, if I have an image, I want it to be labelled according to the latest data point
- only odd windowsize
- GAF: when scaled to [-1, 1] it is not bijective, (arccos on [0,2pi]) -> issue of not being able to recreate time series - if you can recreate ts then maybe you can figure out a missing value inputation
- GAF: right now we scale the series per window - is that a good approach?
    -> yes, because than the images are independent
    -> yes, it also solves the issue of having to create images for every CV round
    -> picture should not be dependent on entire distribution of data
    -> no, because then the picture is not specific for a dataset?
    -> no, because for small window size there will be a 1, a -1 and just a couple meaningful numbers
- I get (floor(label_window_wize/2)) less images, because I don't have labels for those.
- When splitting train and test -> delete overlapping images
- issue of constant series: the image of the action is empty if the series is contant before the action point!!!! - not too long contant series
- eying images:
    -> every sell and buy seems specific for its environment
- idea for the end to potentially increase accuracy: small noise added and duplicate data (distort images)

- if CNN is not enough - what if I use combination of LSTM & CNN
-  maybe color channels different representations?
- average pooling instead of max? https://www.quora.com/What-is-the-benefit-of-using-average-pooling-rather-than-max-pooling
- for potential comparison later: multilayer perceptron
- Maybe Tiled-CNN