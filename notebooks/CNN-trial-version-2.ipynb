{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/test_gemini_BTCUSD_Close_3H_LWS3_IWS20_TrfRP.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image_window_size = np.int(filename[filename.find('_IWS') + 4 : filename.find(\"_Trf\")])\n",
    "Image_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data['images']\n",
    "image_labels = data['image_labels']\n",
    "label_names = data['label_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for quick check: only 1000 images\n",
    "images = images[:1000]\n",
    "image_labels = image_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 19, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 1.0; min: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"max: {}; min: {}\".format(np.amax(images), np.amin(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'Sell', 0: 'Buy', 1: 'Hold'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = label_names.item()\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEICAYAAACj9mr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEatJREFUeJzt3W2MHeV5xvHrYo0xwfgF2xAwToxiC2pHxU1XTipeZN5cY1FMqpCCqsYUKigNUSM1LbSVAkr7AVSltBUE6iQupCJA1EDsJg5gQS2ClBAvyBhTTHGRqdde2WDwYkIQWnz3w5lFy/E87MyZ87r+/yTrnDNz78xzWPtizpmZ53ZECADyHNXpAQDoXgQEgCQCAkASAQEgiYAAkERAAEgiINBUtu+x/fcfsT5sL2jnmNA4AgKHsb3T9oV1y66y/VSnxoTOICAAJBEQKM32b9jeZPuA7RdsX/oRtX9pe8j2HttXt3OcqI6AQCm2j5b0n5Iek3SipK9Ius/26Tm1KyR9TdJFkhZKurC+Bt2NgEDKj7IjhAO2D0j6Vrb8c5KmSro1It6LiCck/VjSlTnb+KKkf4uIbRHxK0m3tGPgaB4CAimXRcSM0T+S/ixbfoqkXRFxaEztq5Lm5mzjFEm76urQQwgIlLVH0jzbY//ufELS7pzaIUnz6urQQwgIlPW0pF9J+ivbR9teJun3JD2QU/sDSVfZXmT7Y5Jubt8w0QwEBEqJiPckXSrpYkmvq/bdxJciYntO7U8l/ZOkJyTtyB7RQ8yEMQBSOIIAkERAAEgiIAAkERAAkiZ1egB5Zs+eHfPnzy9U+8wzz7R2MJgQpk+fXqp+eHi4RSPpHhHh8Wq6MiDmz5+vgYGBQrV9fX2ltn3o0KHxizDhLFu2rFT9unXrWjOQHsNHDABJlQLC9grbL9neYfumnPXH2H4wW/+07flV9gegvRoOCNt9ku5U7Yq6RZKutL2oruwaSW9GxAJJt0u6rdH9AWi/KkcQSyXtiIhXsstvH5C0qq5mlaR7s+f/IekC2+N+MQKgO1QJiLn68K28gzr8lt8PaiJiRNKwpFl5G7N9re0B2wOvvfZahWEBaJYqAZF3JFB/Y0eRmtrCiDUR0R8R/XPmzKkwLADNUiUgBvXhe/1PVW2ugNwa25MkTZf0RoV9AmijKgGxWdJC26fZnizpCknr62rWS1qdPf+CpCeC20eBntHwhVIRMWL7BkmPSuqTtDYiXrD9DUkDEbFe0ncl/bvtHaodOVzRjEEDaI+unA/Cdhx1VLGDm/fff7/Utp988snCtZs3by617TImT55cqn7x4sWFa+fOzZseMu2MM84oVY+Jocil1lxJCSCJgACQREAASCIgACQREACSCAgASQQEgCQCAkASAQEgiYAAkERAAEjqylmtpeKzT5e5t0KSzj333MK13TT51ZYtWwrX9vf3t3AkOJJwBAEgiYAAkERAAEgiIAAkERAAkggIAEkEBIAkAgJAUpXenPNs/5ftF22/YPvPc2qW2R62vSX78/VqwwXQTlWupByR9BcR8azt4yU9Y3tjRPx3Xd3PIuKSCvsB0CFV+mIMSRrKnh+0/aJqvTjrA6Klyk5NX+by6XPOOafscAobGRkpVX/w4MHCtZs2bSo5GiBfU76DsD1f0m9Jejpn9e/Yfs72T20nmzuMbd7bjDEBqK7yzVq2p0r6oaSvRsRbdauflfTJiHjb9kpJP5K0MG87EbFG0ppsm93XzQc4AlU6grB9tGrhcF9EPFS/PiLeioi3s+cbJB1te3aVfQJonypnMaxa780XI+IfEzUfz+pke2m2v/2N7hNAe1X5iHGWpD+S9Lzt0ckK/kbSJyQpIu5WraP39bZHJP1a0hV09wZ6R5WzGE9J+shTAhFxh6Q7Gt0HgM7iSkoASQQEgCQCAkASAQEgiYAAkERAAEgiIAAkERAAkggIAEkEBIAkAgJAEgEBIImAAJBEQABIIiAAJBEQAJIqT1rbaZMnT27ZtstOTV/GpEnl/tNPmTKlcO0777xTdjhALo4gACQREACSKgeE7Z22n896bx7W9MY1/2J7h+2ttj9TdZ8A2qNZ30GcFxGvJ9ZdrFqznIWSPivpruwRQJdrx0eMVZK+FzW/kDTD9slt2C+AipoRECHpMdvP2L42Z/1cSbvGvB7Mln0IvTmB7tOMjxhnRcQe2ydK2mh7e0Q8OWZ9Xu+Mw5rn0JsT6D6VjyAiYk/2uE/Sw5KW1pUMSpo35vWpkvZU3S+A1qvavPc428ePPpe0XNK2urL1kr6Unc34nKThiBiqsl8A7VH1I8ZJkh7O+vNOkvT9iHjE9p9KH/Tn3CBppaQdkt6R9McV9wmgTSoFRES8IunMnOV3j3kekr5cZT8AOqPn78VYvHhxqfotW7aMX5Q5ePBg2eEUVubeCkk6//zzC9euXbu27HCAXFxqDSCJgACQREAASCIgACQREACSCAgASQQEgCQCAkASAQEgiYAAkOTarRLdpcx8ENu3by+17ZNPLj6Z1aZNm0ptu4yjjiqXzfv27Stce/XVV5fadnazHY4wETHuL54jCABJBASAJAICQBIBASCJgACQREAASCIgACQREACSGg4I26dnDXtH/7xl+6t1NctsD4+p+Xr1IQNol4YnrY2IlyQtkSTbfZJ2q9Y4p97PIuKSRvcDoHOa9RHjAkn/GxGvNml7ALpAU+7FsL1W0rMRcUfd8mWSfqha+709kr4WES8ktnGtpNHmv79deVAorMzfAe7bmDiK3ItROSBsT1btH//iiNhbt26apEMR8bbtlZL+OSIWFthm991BNoEREEemdt2sdbFqRw9761dExFsR8Xb2fIOko23PbsI+AbRBMwLiSkn3562w/XFn/8uxvTTb3/4m7BNAG1RqvWf7Y5IuknTdmGVjG/d+QdL1tkck/VrSFdGNE1AAyNXzE8agOr6DODIxYQyASggIAEkEBIAkAgJAEgEBIKnSaU5MDGXOTJQ968VZj97GEQSAJAICQBIBASCJgACQREAASCIgACQREACSCAgASQQEgCQCAkASAQEgiXsxUErZeyvK3Lvx5ptvltr2McccU7h2wYIFpbY9c+bMwrUPPfRQqW3PmTOncO3ll19eattPPPFEqfrxcAQBIKlQQNhea3uf7W1jlp1ge6Ptl7PH3Mi1vTqredn26mYNHEDrFT2CuEfSirplN0l6PGuE83j2+kNsnyDpZkmflbRU0s2pIAHQfQoFREQ8KemNusWrJN2bPb9X0mU5P/q7kjZGxBsR8aakjTo8aAB0qSrfQZwUEUOSlD2emFMzV9KuMa8Hs2UAekCrz2LkfeWd+7V2XfNeAF2gyhHEXtsnS1L2uC+nZlDSvDGvT1Wt0e9hImJNRPRHRH+FMQFooioBsV7S6FmJ1ZLW5dQ8Kmm57ZnZl5PLs2UAekDR05z3S/q5pNNtD9q+RtKtki6y/bJq/TlvzWr7bX9HkiLiDUl/J2lz9ucb2TIAPaDQdxARcWVi1QU5tQOS/mTM67WS1jY0OgAdxaXWaKkyl0+XubxZkt59993CtbNmzSq17V27do1flNm/f3+pbZd5n0NDQ6W23Wxcag0giYAAkERAAEgiIAAkERAAkggIAEkEBIAkAgJAEgEBIImAAJBEQABI4l4MtFSZqenL3FshSVOmTClcW3a6/hkzZhSunTp1aqltlxl3X19fqW03G0cQAJIICABJBASAJAICQBIBASCJgACQREAASBo3IBKNe//B9nbbW20/bDv3pLHtnbaft73F9kAzBw6g9YocQdyjw/tpbpT06Yj4TUn/I+mvP+Lnz4uIJTTEAXrPuAGR17g3Ih6LiJHs5S9U65gFYIJpxqXWV0t6MLEuJD1mOyT9a0SsSW1kbG/OY489VsuXLy+083Xr8hp6oVssWLCgcG3ZqenLXD69devWlm37+uuvL7XtadOmFa7dtm3b+EUtVCkgbP+tpBFJ9yVKzoqIPbZPlLTR9vbsiOQwWXiskaQZM2bkNvgF0F4Nn8WwvVrSJZL+MCJy/0FHxJ7scZ+khyUtbXR/ANqvoYCwvULSjZIujYh3EjXH2T5+9LlqjXs7e7wEoJQipznzGvfeIel41T42bLF9d1Z7iu0N2Y+eJOkp289J+qWkn0TEIy15FwBaYtzvIBKNe7+bqN0jaWX2/BVJZ1YaHYCO4kpKAEkEBIAkAgJAEgEBIImAAJBEQABI6spp74eHh7nHYoKYOXNm4dpdu3aV2naZqenLTnufuDg414033lhq25s3by5V30kcQQBIIiAAJBEQAJIICABJBASAJAICQBIBASCJgACQREAASCIgACS5zCWl7ZJNk48JYPv27YVr9+/fX2rbU6dOLVxbdmr6s88+u3DtbbfdVmrbu3fvLly7ePHiUtseHh4uXBsR415/zhEEgCQCAkBSo817b7G9O5vReovtlYmfXWH7Jds7bN/UzIEDaL1Gm/dK0u1ZU94lEbGhfqXtPkl3SrpY0iJJV9peVGWwANqroea9BS2VtCMiXomI9yQ9IGlVA9sB0CFVvoO4wfbW7CNI3qwgcyWNnQFkMFuWy/a1tgdsD1QYE4AmajQg7pL0KUlLJA1J+mZOTd4plOTpy4hYExH9EdHf4JgANFlDAREReyPi/Yg4JOnbym/KOyhp3pjXp0ra08j+AHRGo817Tx7z8vPKb8q7WdJC26fZnizpCknrG9kfgM4Yd9LarHnvMkmzbQ9KulnSMttLVPvIsFPSdVntKZK+ExErI2LE9g2SHpXUJ2ltRLzQkncBoCVa1rw3e71B0mGnQAH0hq6c9h4Tx5w5cwrXlpkiX5KmTJlSuHbatGmltl1mavoy91ZI0ty5yZN5h5k0qbP/RLnUGkASAQEgiYAAkERAAEgiIAAkERAAkggIAEkEBIAkAgJAEgEBIIlp79FS559/fuHaoaGhUtvu6+srXLttW94Nx80xffr0UvVlLp9+/fXXS2179uzZheoOHDigkZERpr0H0DgCAkASAQEgiYAAkERAAEgiIAAkERAAkopMWrtW0iWS9kXEp7NlD0o6PSuZIelARCzJ+dmdkg5Kel/SCD0vgN5S5IqNeyTdIel7owsi4g9Gn9v+pqThj/j58yKi3NUeALpCkVmtn7Q9P2+dbUv6oqTil8sB6BlVv4M4R9LeiHg5sT4kPWb7GdvXftSG6M0JdJ9C92JkRxA/Hv0OYszyu1Tr4J3Xm1O2T4mIPbZPlLRR0leybuHj7Y97MQBJs2bNKlVf9N6N/v5+DQwMtO5eDNuTJP2+pAdTNVkjHUXEPkkPK7+HJ4AuVeUjxoWStkfEYN5K28fZPn70uaTlyu/hCaBLjRsQWW/On0s63fag7WuyVVdIur+u9hTbo632TpL0lO3nJP1S0k8i4pHmDR1AqzXam1MRcVXOsg96c0bEK5LOrDg+AB3ElZQAkggIAEkEBIAkAgJAEgEBIImAAJDUrdPevybp1brFsyUdCXeFHgnvk/fYeZ+MiDnjFXVlQOSxPXAkzCdxJLxP3mPv4CMGgCQCAkBSLwXEmk4PoE2OhPfJe+wRPfMdBID266UjCABtRkAASOqJgLC9wvZLtnfYvqnT42kF2zttP297y0Sal9P2Wtv7bG8bs+wE2xttv5w9zuzkGKtKvMdbbO/Ofp9bbK/s5Bgb1fUBYbtP0p2SLpa0SNKVthd1dlQtc15ELJkI58/HuEfSirplN0l6PCIWSno8e93L7tHh71GSbs9+n0siYkPO+q7X9QGh2jyWOyLilYh4T9IDklZ1eEwoKJuk+I26xask3Zs9v1fSZW0dVJMl3uOE0AsBMVfSrjGvB7NlE03hFgETwEkRMSRJ2eOJHR5Pq9xge2v2EaQnP0b1QkDkTc09Ec/NnhURn1Hto9SXbZ/b6QGhkrskfUrSEklDknJbQ3S7XgiIQUnzxrw+VdKeDo2lZY6wFgF7bZ8sSdnjvg6Pp+kiYm9EvB8RhyR9Wz36++yFgNgsaaHt02xPVm027fUdHlNTHYEtAtZLWp09Xy1pXQfH0hKjAZj5vHr091mkeW9HRcSI7RskPSqpT9LaiHihw8NqtpMkPVxrdapJkr4/UVoEZG0TlkmabXtQ0s2SbpX0g6yFwv9JurxzI6wu8R6X2V6i2sfhnZKu69gAK+BSawBJvfARA0CHEBAAkggIAEkEBIAkAgJAEgEBIImAAJD0/87v3yy5tkySAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, image in enumerate(images[:2]):\n",
    "    plt.imshow(image, cmap = \"Greys\")\n",
    "    plt.title(label_names[np.int(np.argwhere(image_labels[idx]))])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - test split without overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_test, image_labels_train, image_labels_test = train_test_split(images, \n",
    "                                                                                    image_labels, \n",
    "                                                                                    test_size = .2, \n",
    "                                                                                    random_state = 22\n",
    "                                                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to get rid of the first (Image Window Size -1) test data to avoid lookahead bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = images_test[(Image_window_size-1):]\n",
    "image_labels_test = image_labels_test[(Image_window_size-1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape : (800, 19, 19); Train labels shape : (800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape : {}; Train labels shape : {}\".format(images_train.shape, image_labels_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images shape : (181, 19, 19); Test labels shape : (181, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test images shape : {}; Test labels shape : {}\".format(images_test.shape, image_labels_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = images_test.reshape(-1, images_test.shape[1], images_test.shape[2] , 1)\n",
    "images_train = images_train.reshape(-1, images_train.shape[1], images_train.shape[2] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape : (800, 19, 19, 1); Train labels shape : (800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape : {}; Train labels shape : {}\".format(images_train.shape, image_labels_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images shape : (181, 19, 19, 1); Test labels shape : (181, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test images shape : {}; Test labels shape : {}\".format(images_test.shape, image_labels_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Deep CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 200\n",
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image shape (d x d)\n",
    "n_input = images_train.shape[1]\n",
    "\n",
    "# number of classes\n",
    "n_classes =  image_labels_train.shape[1]\n",
    "\n",
    "# dropout\n",
    "dropout = 0.8 # prob. to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders float type\n",
    "#input placeholder\n",
    "x = tf.placeholder(\"float\", [None, n_input, n_input, 1])\n",
    "\n",
    "# output placeholder\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because using conv layer multiple times, we define it as a function (strides should be 1 for the first because it is the image number, the last should be one, because the gray scale image is only one channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgpool2d(x, k = 2):\n",
    "    return tf.nn.avg_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(x, y, mode):\n",
    "    \"\"\"Model function for CNN\"\"\"\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs = x,\n",
    "        filters = 32,\n",
    "        kernel_size = [3, 3],\n",
    "        padding = \"SAME\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #1\n",
    "    pool1 = avgpool2d(conv1, k = 2)\n",
    "    \n",
    "    # Convolutional Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs = pool1,\n",
    "        filters = 64,\n",
    "        kernel_size = [3, 3],\n",
    "        padding = \"SAME\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    # Pooling layer #2\n",
    "    pool2 = avgpool2d(conv2, k = 2)\n",
    "    \n",
    "    # Convolutional Layer #3\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs = pool2,\n",
    "        filters = 128,\n",
    "        kernel_size = [3, 3],\n",
    "        padding = \"SAME\",\n",
    "        activation = tf.nn.relu)\n",
    "    \n",
    "    # Pooling layer #3\n",
    "    pool3 = avgpool2d(conv3, k = 2)\n",
    "    \n",
    "    # Dense Layer\n",
    "    pool3_flat = tf.reshape(pool3, [-1, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier initialization: Xavier Glorot & Yoshua Bengio (2010), designed to keep the scale of the gradients roughly the same in all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'wc1' : tf.get_variable('W0', shape = (3, 3, 1, 32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wc2' : tf.get_variable('W1', shape = (3, 3, 32, 64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wc3' : tf.get_variable('W2', shape = (3, 3, 64, 128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wd1' : tf.get_variable('W3', shape = (4*4*128, 128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out' : tf.get_variable('W4', shape = (128, n_classes), initializer=tf.contrib.layers.xavier_initializer())\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1' : tf.get_variable('B0', shape = (32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2' : tf.get_variable('B1', shape = (64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3' : tf.get_variable('B2', shape = (128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1' : tf.get_variable('B3', shape = (128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out' : tf.get_variable('B4', shape = (n_classes), initializer=tf.contrib.layers.xavier_initializer())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # here we call conv2d fct. and pass input image x, weights wc1, bias bc1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Avg. pooling (down-sampling), this chooses the avg value of a 2*2 matrix window and outputs a 10*10 matrix (ceil(image_size/2))\n",
    "    conv1 = avgpool2d(conv1, k = 2) # could be maxpooling\n",
    "    \n",
    "    # Convolution layer\n",
    "    \n",
    "    # call conv2d, pass input conv1, weights wc2, biases bc2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Avg. pooling (down-sampling), this chooses the avg value of a 2*2 matrix window and outputs a ceil(conv1_len/2) * ceil(conv1_len/2)  matrix\n",
    "    conv2 = avgpool2d(conv2, k = 2)\n",
    "    \n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Avg. pooling (down-sampling), this chooses the avg value of a 2*2 matrix window and outputs a ceil(conv2_len/2)*ceil(conv2_len/2) matrix\n",
    "    conv3 = avgpool2d(conv3, k = 2)\n",
    "    \n",
    "    \n",
    "    # Fully Connected Layer (Dense)\n",
    "    # REshape conv3 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "     # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and bias term for the out\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimizer Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss funciton here is cross entropy, with the reasoning that it's a fitting loss function due to always being positive and tending towards zero if the neuron gets better in guessing the right label and because it recovers faster from wrong intializations and the learning doesnt slow down\n",
    "\n",
    "Avg. loss over batches to get a  single loss - maybe weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-c1cfd6889586>:26: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U can save a graph and run testing on it later\n",
    "\n",
    "ACCURACY CAN BE CHANGED TO OTHER MEASURE LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wether the index of the maximum value of the predicted image is equal to the actual labelled image - both will be a column vector\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "# Calculate accuracy across all given images and average them\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the vars\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int(np.ceil(len(images_train)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(32, 19, 19, 1) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "for batch in range(np.int(np.ceil(len(images_train)/batch_size))):\n",
    "            batch_x = images_train[batch*batch_size:min((batch+1)*batch_size, len(images_train))]\n",
    "            batch_y = image_labels_train[batch*batch_size:min((batch+1)*batch_size, len(image_labels_train))]\n",
    "            \n",
    "            print(batch_x.shape, batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be broadcastable: logits_size=[72,3] labels_size=[128,3]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-27-0aafd0515c66>:3) ]]\n\nCaused by op 'softmax_cross_entropy_with_logits', defined at:\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n    handle._run()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1080, in __init__\n    self.run()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-0aafd0515c66>\", line 3, in <module>\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 9669, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[72,3] labels_size=[128,3]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-27-0aafd0515c66>:3) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[72,3] labels_size=[128,3]\n\t [[{{node softmax_cross_entropy_with_logits}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8849f0f9ee21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m# Run optimization op (backprop)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m# Calculate batch loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             loss, acc = sess.run([cost, accuracy], feed_dict = {x : batch_x,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[72,3] labels_size=[128,3]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-27-0aafd0515c66>:3) ]]\n\nCaused by op 'softmax_cross_entropy_with_logits', defined at:\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n    handle._run()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1080, in __init__\n    self.run()\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-0aafd0515c66>\", line 3, in <module>\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2471, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 9669, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be broadcastable: logits_size=[72,3] labels_size=[128,3]\n\t [[node softmax_cross_entropy_with_logits (defined at <ipython-input-27-0aafd0515c66>:3) ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(np.int(np.ceil(len(images_train)/batch_size))):\n",
    "            batch_x = images_train[batch*batch_size : min((batch+1)*batch_size, len(images_train))]\n",
    "            batch_y = image_labels_train[batch*batch_size : min((batch+1)*batch_size, len(image_labels_train))]\n",
    "            \n",
    "            # Run optimization op (backprop)\n",
    "            # Calculate batch loss and accuracy\n",
    "            sess.run(optimizer, feed_dict = {x : batch_x, y : batch_y, keep_prob: dropout})\n",
    "            \n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict = {x : batch_x,\n",
    "                                                                y : batch_y,\n",
    "                                                                keep_prob: 1.})\n",
    "        print(\"Iter \" + str(i) + \", Loss = \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy = \" + \\\n",
    "              \"{:.5f}\".format(acc)\n",
    "             )\n",
    "        print('Optimization Finished!')\n",
    "\n",
    "        # Calculate accuracy for all test images\n",
    "        test_acc, valid_loss = sess.run([accuracy, cost], feed_dict = {x : images_test,\n",
    "                                                                       y : image_labels_test})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print('Testing Accuracy: ', \"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
