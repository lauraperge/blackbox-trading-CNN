{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/test_gemini_BTCUSD_Close_3H_LWS3_IWS20_TrfRP.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image_window_size = np.int(filename[filename.find('_IWS') + 4 : filename.find(\"_Trf\")])\n",
    "Image_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data['images']\n",
    "image_labels = data['image_labels']\n",
    "label_names = data['label_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for quick check: only 1000 images\n",
    "images = images[:1000]\n",
    "image_labels = image_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 19, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 1.0; min: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"max: {}; min: {}\".format(np.amax(images), np.amin(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'Sell', 0: 'Buy', 1: 'Hold'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = label_names.item()\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEICAYAAACj9mr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEkpJREFUeJzt3X+s1fV9x/Hni4uILVdFQapIpSlEB2Sy7oZ2MRq01qFx0i61aJYVq4mdq82a2E23JbVZ1qRm6bpsOC1tmXZpq92KhbW0SnTEmrSWq6GIK05G6LhwI4q/UFr1ynt/nO/tjofvx/v9nu/5yX09kptzzve8z+f7ObmXF9/vOd/v962IwMwsz5RuT8DMepcDwsySHBBmluSAMLMkB4SZJTkgzCzJAWEtJekuSX/7Ns+HpAWdnJM1zwFhR5G0R9LFDcuukfRIt+Zk3eGAMLMkB4SVJum3JG2R9KKkJyVd8Ta1fy5pVNJ+Sdd2cp5WnQPCSpF0HPAfwAPAacCngW9KOjundgXwWeBDwELg4sYa620OCEv5XraF8KKkF4F/zpZ/AJgBfDEiXo+Ih4DvA1fnjPEx4F8iYkdEvAp8vhMTt9ZxQFjKhyPi5PEf4E+z5WcAeyPiSF3tL4G5OWOcAextqLM+4oCwsvYD8yTV/+28G9iXUzsKzGuosz7igLCyHgVeBf5C0nGSlgN/ANyTU/sd4BpJiyS9A7i1c9O0VnBAWCkR8TpwBXAp8By1zyY+HhE7c2p/CPwD8BCwK7u1PiJfMMbMUrwFYWZJDggzS3JAmFmSA8LMkqZ2ewJ5Zs2aFfPnzy9U+9hjj7V3MtYxs2fPLlV/5MiRiYsyAwMDpcaeMqX4/50nnHBC28Z+7bXXSo09MjJSuDYiNFFNTwbE/PnzGR4eLlRb9hdf5o/KOmvVqlWl6g8fPly4dsaMGaXGHhwcLFy7ZMmSUmNPnz69cO3u3btLjX3TTTeVqp+IdzHMLKlSQEhaIekpSbsk3ZLz/PGS7s2ef1TS/CrrM7POajogJA0At1M7om4RcLWkRQ1l1wEvRMQC4MvAbc2uz8w6r8oWxDJgV0Tszg6/vQdY2VCzErg7u//vwAclTfjBiJn1hioBMZe3nso7wtGn/P6mJiLGgJeAU/MGk3S9pGFJw88++2yFaZlZq1QJiLwtgcYTO4rU1BZGrI2IoYgYKvt1l5m1R5WAGOGt5/qfSe1aAbk1kqYCJwHPV1inmXVQlYDYCiyU9B5J04CrgI0NNRuB1dn9jwIPhU8fNesbTR8oFRFjkm4E7gcGgHUR8aSkvwGGI2Ij8HXgXyXtorblcFUrJm1mndGT14OQFEUPR33zzTdLjV3myEsfdTl5rVzZ+IVc2oYNG9o4k/Ypcqi1j6Q0syQHhJklOSDMLMkBYWZJDggzS3JAmFmSA8LMkhwQZpbkgDCzJAeEmSU5IMwsqWfPxShaW+YS4lDu3I2HH3641Nhbt24tVV/GtGnTCtcuXry41Nhz5zZe5yftnHPOKTW29S6fi2FmlTggzCzJAWFmSQ4IM0tyQJhZkgPCzJIcEGaW5IAws6QqvTnnSfpPSb+Q9KSkP8upWS7pJUnbsp/PVZuumXVS05e9B8aAmyLicUmDwGOSNkfEfzXU/TgiLq+wHjPrkip9MUaB0ez+IUm/oNaLszEg2qrspenLHD59wQUXlBq7V/oSb9u2rVT90NBQm2Zi/a4ln0FImg/8DvBoztO/J+nnkn4oKXmSQH3z3lbMycyqq7KLAYCkGcB3gc9ExMsNTz8OnBURr0i6DPgesDBvnIhYC6zNxuy9M8jMJqFKWxCSjqMWDt+MiPWNz0fEyxHxSnZ/E3CcpFlV1mlmnVPlWwxR6735i4j4+0TNu7I6JC3L1new2XWaWWdV2cU4D/hj4AlJ45+K/RXwboCIuJNaR+8bJI0BvwKucndvs/5R5VuMR4C3/dg+ItYAa5pdh5l1l4+kNLMkB4SZJTkgzCzJAWFmSQ4IM0uqfCRlvylzafqy51acf/75ZadT2NjYWOHaQ4cOlRp7y5YtJWdjk4W3IMwsyQFhZkkOCDNLckCYWZIDwsySHBBmluSAMLMkB4SZJTkgzCzJAWFmSQ4IM0tyQJhZkgPCzJIqB4SkPZKeyHpvHtX0RjX/KGmXpO2S3ld1nWbWGa063fvCiHgu8dyl1JrlLATeD9yR3ZpZj+vELsZK4BtR81PgZEmnd2C9ZlZRKwIigAckPSbp+pzn5wJ76x6PZMvewr05zXpPK3YxzouI/ZJOAzZL2hkR9S208y7LdFTzHPfmNOs9lbcgImJ/dnsAuA9Y1lAyAsyre3wmsL/qes2s/ao2732npMHx+8AlwI6Gso3Ax7NvMz4AvBQRo1XWa2adUXUXYw5wX3Zx16nAtyLiR5L+BH7Tn3MTcBmwCzgMfKLiOs2sQyoFRETsBs7NWX5n3f0APlVlPWbWHZPusvfTpk1r29hlLk1f1tSpxX9V06dPLzX24cOHy07HJgkfam1mSQ4IM0tyQJhZkgPCzJIcEGaW5IAwsyQHhJklOSDMLMkBYWZJDggzS5p0h1ovXry4cO22bdtKjX3o0KGy0ymszOHTF110Uamx161bV3Y6Nkl4C8LMkhwQZpbkgDCzJAeEmSU5IMwsyQFhZkkOCDNLckCYWVLTASHp7Kxh7/jPy5I+01CzXNJLdTWfqz5lM+uUpo+kjIingKUAkgaAfdQa5zT6cURc3ux6zKx7WrWL8UHgfyLily0az8x6gGptKyoOIq0DHo+INQ3LlwPfpdZ+bz/w2Yh4MjHG9cB489/frTyphJ07dxauPf30ck3It2zZUnI2xU2ZUjzLDxw4UGrsa6+9tnBt1iTJjgERMeEvs/IWhKRpwBXAv+U8/ThwVkScC/wT8L3UOBGxNiKGImKo6pzMrDVasYtxKbWth2can4iIlyPilez+JuA4SbNasE4z64BWBMTVwLfznpD0LmXbpJKWZes72IJ1mlkHVLoehKR3AB8CPlm3rL5x70eBGySNAb8CropWfOhhZh1RtXnvYeDUhmX1jXvXAGsaX2dm/cFHUppZkgPCzJIcEGaW5IAwsyQHhJklteRQ61aT1HuTMgDK/r340Oze1ZFDrc3s2OWAMLMkB4SZJTkgzCzJAWFmSQ4IM0tyQJhZkgPCzJIcEGaW5IAwsyQHhJklVbqilE0+Zc+tKHPuhs/b6D3egjCzpEIBIWmdpAOSdtQtO0XSZklPZ7czE69dndU8LWl1qyZuZu1XdAviLmBFw7JbgAcjYiHwYPb4LSSdAtwKvB9YBtyaChIz6z2FAiIiHgaeb1i8Erg7u3838OGcl/4+sDkino+IF4DNHB00ZtajqnwGMSciRgGy29NyauYCe+sej2TLzKwPtPtbjLyPpXM/1m5o3mtmPaDKFsQzkk4HyG7zWkqPAPPqHp9Jrcv3Udy816z3VAmIjcD4txKrgQ05NfcDl0iamX04eUm2zMz6QURM+EOtOe8o8Aa1rYLrqLXcexB4Ors9JasdAr5W99prgV3ZzycKri/8c2z8lNHtuU62nyL/Fn1Va2srH0nZu4pc1bonD7WePXs2q1atKlS7Zo17A/eyMv/oy/5n9cILLxSuPf7440uNvWDBgsK1M2eWO7Rn/fr1hWtnz55dauwrr7yyUN3WrVsL1flQazNLckCYWZIDwsySHBBmluSAMLMkB4SZJTkgzCzJAWFmSQ4IM0tyQJhZkgPCzJJ68lyMI0eOcPjw4W5PwzqszLkVUO4ciF//+telxj711FML1+7du3fiojoHDx4sXFv2PI/R0dFCdW+88UahOm9BmFmSA8LMkhwQZpbkgDCzJAeEmSU5IMwsyQFhZkkTBkSice/fSdopabuk+ySdnHjtHklPSNomabiVEzez9iuyBXEXR/fT3AwsiYjfBv4b+Mu3ef2FEbHUDXHM+s+EAZHXuDciHoiIsezhT6l1zDKzY0wrDrW+Frg38VwAD2R9Lr4SEWtTg9T35hwcHGTGjBktmJr1k7KXpi9z+PT06dNLjV3mcv0nn5y7h51U5m+77LwHBgZK1U+kUkBI+mtgDPhmouS8iNgv6TRgs6Sd2RbJUbLwWAswZ84cN84x6wFNf4shaTVwOfBHkeh4EhH7s9sDwH3AsmbXZ2ad11RASFoB3AxcERG5p11KeqekwfH71Br37sirNbPeVORrzm8DPwHOljQi6TpgDTBIbbdhm6Q7s9ozJG3KXjoHeETSz4GfAT+IiB+15V2YWVtM+BlERFyds/jridr9wGXZ/d3AuZVmZ2Zd5SMpzSzJAWFmSQ4IM0tyQJhZkgPCzJIcEGaW1JOXvZ8yZQqDg4OFaleuXFlq7A0bNjQzJeuABQsWlKovc2n6MudWAGzfvr1tY99www2Fa0888cRSY+/Y0dpjEb0FYWZJDggzS3JAmFmSA8LMkhwQZpbkgDCzJAeEmSU5IMwsyQFhZkkOCDNL6slDrU844QSWLFlSqPYLX/hCm2djnTJz5sxS9Xv37i1cW/bS9GUOn05csznp5ptvLly7devWUmO3mrcgzCzJAWFmSc027/28pH3ZFa23Sbos8doVkp6StEvSLa2cuJm1X7PNewG+nDXlXRoRmxqflDQA3A5cCiwCrpa0qMpkzayzmmreW9AyYFdE7I6I14F7gHIXbzCzrqryGcSNkrZnuyB5Hz/PBeo/Zh7JluWSdL2kYUnDhw4dqjAtM2uVZgPiDuC9wFJgFPhSTk3e90TJ74MiYm1EDEXEUNGrSZlZezUVEBHxTES8GRFHgK+S35R3BJhX9/hMYH8z6zOz7mi2ee/pdQ8/Qn5T3q3AQknvkTQNuArY2Mz6zKw7JjySMmveuxyYJWkEuBVYLmkptV2GPcAns9ozgK9FxGURMSbpRuB+YABYFxFPtuVdmFlbtK15b/Z4E3DUV6Bm1h968lyMKVOmMH369G5Pwzps/fr1peoPHjxYuHbGjBmlxi5zafoy51YA3HbbbYVr9+3bV2rsxYsXF6p75ZVXCtX5UGszS3JAmFmSA8LMkhwQZpbkgDCzJAeEmSU5IMwsyQFhZkkOCDNLckCYWVJPHmr92muvsXv37m5Pwzps9uzZperLXCa/7KH7J554YuHaspemL3P49Ny5yWss5Zo6tbX/pL0FYWZJDggzS3JAmFmSA8LMkhwQZpbkgDCzJAeEmSUVuWjtOuBy4EBELMmW3QucnZWcDLwYEUtzXrsHOAS8CYxFxFCL5m1mHVDkqIq7gDXAN8YXRMSq8fuSvgS89DavvzAinmt2gmbWPUWuav2wpPl5z0kS8DHgotZOy8x6QdXPIM4HnomIpxPPB/CApMckXf92A9X35nz11VcrTsvMWkERyXaZ/19U24L4/vhnEHXL76DWwTuvNyeSzoiI/ZJOAzYDn866hU+0voknZceciy4qtyE6OjpauHZgYKDU2Dt25DWLa42TTjqpcG3Zcyuee67Y3vzQ0BDDw8N5/XPfouktCElTgT8E7k3VZI10iIgDwH3k9/A0sx5VZRfjYmBnRIzkPSnpnZIGx+8Dl5Dfw9PMetSEAZH15vwJcLakEUnXZU9dBXy7ofYMSeOt9uYAj0j6OfAz4AcR8aPWTd3M2q3Z3pxExDU5y37TmzMidgPnVpyfmXWRj6Q0syQHhJklOSDMLMkBYWZJDggzS3JAmFlSoUOtO03Ss8AvGxbPAibDWaGT4X36PXbfWRExYZ+BngyIPJKGJ8P1JCbD+/R77B/exTCzJAeEmSX1U0Cs7fYEOmQyvE+/xz7RN59BmFnn9dMWhJl1mAPCzJL6IiAkrZD0lKRdkm7p9nzaQdIeSU9I2iZpuNvzaRVJ6yQdkLSjbtkpkjZLejq7ndnNOVaVeI+fl7Qv+31uk3RZN+fYrJ4PCEkDwO3ApcAi4GpJi7o7q7a5MCKWHgvfn9e5C1jRsOwW4MGIWAg8mD3uZ3dx9HsE+HL2+1waEZtynu95PR8Q1K5juSsidkfE68A9wMouz8kKyi5S/HzD4pXA3dn9u4EPd3RSLZZ4j8eEfgiIucDeuscj2bJjTeEWAceAORExCpDdntbl+bTLjZK2Z7sgfbkb1Q8BkXdp7mPxu9nzIuJ91HalPiXpgm5PyCq5A3gvsBQYBXJbQ/S6fgiIEWBe3eMzgf1dmkvbTLIWAc9IOh0guz3Q5fm0XEQ8ExFvRsQR4Kv06e+zHwJiK7BQ0nskTaN2Ne2NXZ5TS03CFgEbgdXZ/dXAhi7OpS3GAzDzEfr091mubU8XRMSYpBuB+4EBYF1EPNnlabXaHOC+WqtTpgLfOlZaBGRtE5YDsySNALcCXwS+k7VQ+F/gyu7NsLrEe1wuaSm13eE9wCe7NsEKfKi1mSX1wy6GmXWJA8LMkhwQZpbkgDCzJAeEmSU5IMwsyQFhZkn/BzS/QXtxQNHlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, image in enumerate(images[:2]):\n",
    "    plt.imshow(image, cmap = \"Greys\")\n",
    "    plt.title(label_names[np.int(np.argwhere(image_labels[idx]))])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - test split without overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_test, image_labels_train, image_labels_test = train_test_split(images, \n",
    "                                                                                    image_labels, \n",
    "                                                                                    test_size = .2, \n",
    "                                                                                    random_state = 22\n",
    "                                                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to get rid of the first (Image Window Size -1) test data to avoid lookahead bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = images_test[(Image_window_size-1):]\n",
    "image_labels_test = image_labels_test[(Image_window_size-1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape : (800, 19, 19); Train labels shape : (800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape : {}; Train labels shape : {}\".format(images_train.shape, image_labels_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images shape : (181, 19, 19); Test labels shape : (181, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test images shape : {}; Test labels shape : {}\".format(images_test.shape, image_labels_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = images_test.reshape(-1, images_test.shape[1], images_test.shape[2] , 1)\n",
    "images_train = images_train.reshape(-1, images_train.shape[1], images_train.shape[2] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape : (800, 19, 19, 1); Train labels shape : (800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape : {}; Train labels shape : {}\".format(images_train.shape, image_labels_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images shape : (181, 19, 19, 1); Test labels shape : (181, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test images shape : {}; Test labels shape : {}\".format(images_test.shape, image_labels_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Deep CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 200\n",
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image shape (d x d)\n",
    "n_input = images_train.shape[1]\n",
    "\n",
    "# number of classes\n",
    "n_classes =  image_labels_train.shape[1]\n",
    "\n",
    "# dropout\n",
    "dropout = 0.8 # prob. to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders float type\n",
    "#input placeholder\n",
    "x = tf.placeholder(\"float\", [None, n_input, n_input, 1])\n",
    "\n",
    "# output placeholder\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because using conv layer multiple times, we define it as a function (strides should be 1 for the first because it is the image number, the last should be one, because the gray scale image is only one channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides = 1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides =[1, strides, strides, 1], padding = 'SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) # activation ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgpool2d(x, k = 2):\n",
    "    return tf.nn.avg_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier initialization: Xavier Glorot & Yoshua Bengio (2010), designed to keep the scale of the gradients roughly the same in all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Corvinus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'wc1' : tf.get_variable('W0', shape = (3, 3, 1, 32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wc2' : tf.get_variable('W1', shape = (3, 3, 32, 64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wc3' : tf.get_variable('W2', shape = (3, 3, 64, 128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wd1' : tf.get_variable('W3', shape = (3*3*128, 128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out' : tf.get_variable('W4', shape = (128, n_classes), initializer=tf.contrib.layers.xavier_initializer())\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1' : tf.get_variable('B0', shape = (32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2' : tf.get_variable('B1', shape = (64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3' : tf.get_variable('B2', shape = (128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1' : tf.get_variable('B3', shape = (128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out' : tf.get_variable('B4', shape = (n_classes), initializer=tf.contrib.layers.xavier_initializer())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # here we call conv2d fct. and pass input image x, weights wc1, bias bc1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Avg. pooling (down-sampling), this chooses the avg value of a 2*2 matrix window and outputs a 10*10 matrix (ceil(image_size/2))\n",
    "    conv1 = avgpool2d(conv1, k = 2) # could be maxpooling\n",
    "    \n",
    "    # Convolution layer\n",
    "    \n",
    "    # call conv2d, pass input conv1, weights wc2, biases bc2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Avg. pooling (down-sampling), this chooses the avg value of a 2*2 matrix window and outputs a ceil(conv1_len/2) * ceil(conv1_len/2)  matrix\n",
    "    conv2 = avgpool2d(conv2, k = 2)\n",
    "    \n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Avg. pooling (down-sampling), this chooses the avg value of a 2*2 matrix window and outputs a ceil(conv2_len/2)*ceil(conv2_len/2) matrix\n",
    "    conv3 = avgpool2d(conv3, k = 2)\n",
    "    \n",
    "    \n",
    "    # Fully Connected Layer (Dense)\n",
    "    # REshape conv3 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "     # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and bias term for the out\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimizer Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss funciton here is cross entropy, with the reasoning that it's a fitting loss function due to always being positive and tending towards zero if the neuron gets better in guessing the right label and because it recovers faster from wrong intializations and the learning doesnt slow down\n",
    "\n",
    "Avg. loss over batches to get a  single loss - maybe weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-c1cfd6889586>:26: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U can save a graph and run testing on it later\n",
    "\n",
    "ACCURACY CAN BE CHANGED TO OTHER MEASURE LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wether the index of the maximum value of the predicted image is equal to the actual labelled image - both will be a column vector\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "# Calculate accuracy across all given images and average them\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the vars\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int(np.ceil(len(images_train)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(128, 19, 19, 1) (128, 3)\n",
      "(32, 19, 19, 1) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "for batch in range(np.int(np.ceil(len(images_train)/batch_size))):\n",
    "            batch_x = images_train[batch*batch_size:min((batch+1)*batch_size, len(images_train))]\n",
    "            batch_y = image_labels_train[batch*batch_size:min((batch+1)*batch_size, len(image_labels_train))]\n",
    "            \n",
    "            print(batch_x.shape, batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss = 1.082297, Training Accuracy = 0.34375\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.28177\n",
      "Iter 1, Loss = 1.103713, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 2, Loss = 1.096647, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 3, Loss = 1.091008, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 4, Loss = 1.091119, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 5, Loss = 1.092422, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 6, Loss = 1.091262, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 7, Loss = 1.091167, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 8, Loss = 1.090894, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 9, Loss = 1.091208, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 10, Loss = 1.092137, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 11, Loss = 1.090809, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 12, Loss = 1.090593, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 13, Loss = 1.091881, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 14, Loss = 1.093347, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 15, Loss = 1.093143, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 16, Loss = 1.091136, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 17, Loss = 1.091178, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 18, Loss = 1.091678, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 19, Loss = 1.089968, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 20, Loss = 1.090367, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 21, Loss = 1.092330, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 22, Loss = 1.092227, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 23, Loss = 1.089262, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 24, Loss = 1.090502, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 25, Loss = 1.090110, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 26, Loss = 1.088687, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 27, Loss = 1.090103, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 28, Loss = 1.089293, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 29, Loss = 1.090261, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 30, Loss = 1.089767, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 31, Loss = 1.087229, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 32, Loss = 1.087106, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 33, Loss = 1.087333, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 34, Loss = 1.087191, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 35, Loss = 1.088420, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 36, Loss = 1.086331, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 37, Loss = 1.088239, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 38, Loss = 1.087201, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 39, Loss = 1.086233, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 40, Loss = 1.084696, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 41, Loss = 1.081042, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 42, Loss = 1.080225, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 43, Loss = 1.080577, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 44, Loss = 1.080415, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 45, Loss = 1.078213, Training Accuracy = 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 46, Loss = 1.075607, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 47, Loss = 1.075762, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 48, Loss = 1.074497, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 49, Loss = 1.072946, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 50, Loss = 1.072632, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 51, Loss = 1.071701, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 52, Loss = 1.068680, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 53, Loss = 1.064540, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 54, Loss = 1.062491, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49724\n",
      "Iter 55, Loss = 1.063193, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49724\n",
      "Iter 56, Loss = 1.059870, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 57, Loss = 1.058644, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 58, Loss = 1.057789, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 59, Loss = 1.054704, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 60, Loss = 1.053192, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 61, Loss = 1.052775, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 62, Loss = 1.048752, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 63, Loss = 1.049744, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49724\n",
      "Iter 64, Loss = 1.046276, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 65, Loss = 1.040365, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 66, Loss = 1.038664, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 67, Loss = 1.037873, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 68, Loss = 1.035555, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 69, Loss = 1.032251, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 70, Loss = 1.030074, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 71, Loss = 1.026146, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 72, Loss = 1.024905, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 73, Loss = 1.023264, Training Accuracy = 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 74, Loss = 1.019962, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 75, Loss = 1.017296, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 76, Loss = 1.015292, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 77, Loss = 1.009409, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 78, Loss = 1.003798, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 79, Loss = 1.003558, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 80, Loss = 0.999136, Training Accuracy = 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 81, Loss = 0.994671, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 82, Loss = 0.994050, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 83, Loss = 0.986476, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 84, Loss = 0.979382, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 85, Loss = 0.975697, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 86, Loss = 0.974671, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 87, Loss = 0.970445, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 88, Loss = 0.962643, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 89, Loss = 0.958300, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 90, Loss = 0.961058, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 91, Loss = 0.951580, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 92, Loss = 0.947245, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 93, Loss = 0.941739, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 94, Loss = 0.938658, Training Accuracy = 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 95, Loss = 0.935655, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 96, Loss = 0.934756, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 97, Loss = 0.921957, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 98, Loss = 0.911439, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 99, Loss = 0.914411, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 100, Loss = 0.905026, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 101, Loss = 0.895153, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 102, Loss = 0.885034, Training Accuracy = 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 103, Loss = 0.877406, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 104, Loss = 0.879631, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 105, Loss = 0.871097, Training Accuracy = 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 106, Loss = 0.869605, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49724\n",
      "Iter 107, Loss = 0.862452, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 108, Loss = 0.861702, Training Accuracy = 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 109, Loss = 0.850554, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.50276\n",
      "Iter 110, Loss = 0.842009, Training Accuracy = 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 111, Loss = 0.838091, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 112, Loss = 0.835078, Training Accuracy = 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 113, Loss = 0.816093, Training Accuracy = 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 114, Loss = 0.806805, Training Accuracy = 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 115, Loss = 0.806982, Training Accuracy = 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 116, Loss = 0.800029, Training Accuracy = 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 117, Loss = 0.792112, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46409\n",
      "Iter 118, Loss = 0.797336, Training Accuracy = 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48066\n",
      "Iter 119, Loss = 0.790243, Training Accuracy = 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 120, Loss = 0.782950, Training Accuracy = 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.49171\n",
      "Iter 121, Loss = 0.780786, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.48619\n",
      "Iter 122, Loss = 0.769481, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 123, Loss = 0.767901, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 124, Loss = 0.774023, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 125, Loss = 0.765268, Training Accuracy = 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46409\n",
      "Iter 126, Loss = 0.752869, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 127, Loss = 0.754274, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 128, Loss = 0.748057, Training Accuracy = 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.44199\n",
      "Iter 129, Loss = 0.741912, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 130, Loss = 0.731543, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.44751\n",
      "Iter 131, Loss = 0.734817, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46409\n",
      "Iter 132, Loss = 0.722506, Training Accuracy = 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46409\n",
      "Iter 133, Loss = 0.731384, Training Accuracy = 0.71875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 134, Loss = 0.723308, Training Accuracy = 0.71875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 135, Loss = 0.735458, Training Accuracy = 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 136, Loss = 0.723129, Training Accuracy = 0.71875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45304\n",
      "Iter 137, Loss = 0.719538, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.41436\n",
      "Iter 138, Loss = 0.704376, Training Accuracy = 0.71875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45304\n",
      "Iter 139, Loss = 0.700673, Training Accuracy = 0.71875\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 140, Loss = 0.710498, Training Accuracy = 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 141, Loss = 0.691739, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45304\n",
      "Iter 142, Loss = 0.687097, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 143, Loss = 0.682065, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46409\n",
      "Iter 144, Loss = 0.681388, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 145, Loss = 0.679733, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 146, Loss = 0.675333, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 147, Loss = 0.658874, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.43646\n",
      "Iter 148, Loss = 0.656250, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 149, Loss = 0.649446, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 150, Loss = 0.649187, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 151, Loss = 0.647535, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.41436\n",
      "Iter 152, Loss = 0.654307, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46409\n",
      "Iter 153, Loss = 0.653427, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45304\n",
      "Iter 154, Loss = 0.643719, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.44751\n",
      "Iter 155, Loss = 0.649427, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.43094\n",
      "Iter 156, Loss = 0.644595, Training Accuracy = 0.78125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.37017\n",
      "Iter 157, Loss = 0.637228, Training Accuracy = 0.78125\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.37017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 158, Loss = 0.637625, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.40884\n",
      "Iter 159, Loss = 0.672533, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.40884\n",
      "Iter 160, Loss = 0.646249, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.41989\n",
      "Iter 161, Loss = 0.646163, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46409\n",
      "Iter 162, Loss = 0.641787, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 163, Loss = 0.623227, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.44751\n",
      "Iter 164, Loss = 0.610325, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n",
      "Iter 165, Loss = 0.591820, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.44751\n",
      "Iter 166, Loss = 0.594964, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 167, Loss = 0.591647, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.44199\n",
      "Iter 168, Loss = 0.584361, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45304\n",
      "Iter 169, Loss = 0.575365, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45856\n",
      "Iter 170, Loss = 0.563691, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.44199\n",
      "Iter 171, Loss = 0.573707, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.47514\n",
      "Iter 172, Loss = 0.560312, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.45304\n",
      "Iter 173, Loss = 0.554942, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46409\n",
      "Iter 174, Loss = 0.564705, Training Accuracy = 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.46961\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(np.int(np.ceil(len(images_train)/batch_size))):\n",
    "            batch_x = images_train[batch*batch_size : min((batch+1)*batch_size, len(images_train))]\n",
    "            batch_y = image_labels_train[batch*batch_size : min((batch+1)*batch_size, len(image_labels_train))]\n",
    "            \n",
    "            # Run optimization op (backprop)\n",
    "            # Calculate batch loss and accuracy\n",
    "            sess.run(optimizer, feed_dict = {x : batch_x, y : batch_y, keep_prob: dropout})\n",
    "            \n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict = {x : batch_x,\n",
    "                                                                y : batch_y,\n",
    "                                                                keep_prob: 1.})\n",
    "        print(\"Iter \" + str(i) + \", Loss = \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy = \" + \\\n",
    "              \"{:.5f}\".format(acc)\n",
    "             )\n",
    "        print('Optimization Finished!')\n",
    "\n",
    "        # Calculate accuracy for all test images\n",
    "        test_acc, valid_loss = sess.run([accuracy, cost], feed_dict = {x : images_test,\n",
    "                                                                       y : image_labels_test,\n",
    "                                                                       keep_prob: 1.})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print('Testing Accuracy: ', \"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
